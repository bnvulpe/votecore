{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "version = sys.version_info\n",
    "if version.major < 3 or (version.major == 3 and version.minor < 10):\n",
    "\traise RuntimeError(\"This script requires Python 3.10 or higher\")\n",
    "import os\n",
    "from typing import Iterable\n",
    "\n",
    "from fileStreams import getFileJsonStream\n",
    "from utils import FileProgressLog\n",
    "import json\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file ../data/raw/reddit/r_politics_posts.jsonl\n",
      "62,822 - 100.00% - elapsed: 829.84ms - remaining: 0s - 13.2µs/row     \n"
     ]
    }
   ],
   "source": [
    "def processPostFile(path: str, only_text: bool = False):\n",
    "\t\n",
    "    new_json = []\n",
    "    post_ids = set()\n",
    "\n",
    "    print(f\"Processing file {path}\")\n",
    "    with open(path, \"rb\") as f:\n",
    "        jsonStream = getFileJsonStream(path, f)\n",
    "        if jsonStream is None:\n",
    "            print(f\"Skipping unknown file {path}\")\n",
    "            return\n",
    "        progressLog = FileProgressLog(path, f)\n",
    "        for row in jsonStream:\n",
    "            progressLog.onRow()\n",
    "            # PUT YOUR CODE HERE\n",
    "            \n",
    "            body = row[\"selftext\"]\n",
    "\n",
    "            if body == \"[deleted]\" or body == \"[removed]\": # skip deleted posts\n",
    "                continue\n",
    "\n",
    "            if only_text:\n",
    "                if body == \"\":\n",
    "                    continue           \n",
    "            # example fields\n",
    "            author = row[\"author\"]\n",
    "            subreddit = row[\"subreddit\"]\n",
    "            subreddit_id = row[\"subreddit_id\"]\n",
    "            id = row[\"id\"]\n",
    "            name = row[\"name\"]\n",
    "            created = row[\"created_utc\"]\n",
    "            datetime_object = datetime.fromtimestamp(created)\n",
    "            score = row[\"score\"]\n",
    "            ratio = row[\"upvote_ratio\"]\n",
    "            title = row[\"title\"]\n",
    "            \n",
    "            url = row[\"url\"]\n",
    "\n",
    "            new_json.append({\n",
    "                \"subreddit\": subreddit,\n",
    "                \"subreddit_id\": subreddit_id,\n",
    "                \"id\": id,\n",
    "                \"name\": name,\n",
    "                \"author\": author,\n",
    "                \"created\": created,\n",
    "                \"datetime\": str(datetime_object),\n",
    "                \"score\": score,\n",
    "                \"ratio\": ratio,\n",
    "                \"title\": title,\n",
    "                \"body\": body,\n",
    "                \"url\": url\n",
    "            })\n",
    "\n",
    "            post_ids.add(name)\n",
    "\n",
    "        progressLog.logProgress(\"\\n\")\n",
    "    with open(f'../data/filtered/posts/r_{subreddit}_posts.json', \"w\") as f:\n",
    "        for row in new_json:\n",
    "            f.write(json.dumps(row))\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "    with open(f'../data/filtered/posts/r_{subreddit}_post_ids.txt', \"w\") as f:\n",
    "        for id in post_ids:\n",
    "            f.write(f\"{id}\")\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "path = '../data/raw/reddit/r_politics_posts.jsonl'\n",
    "processPostFile(path, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file ../data/raw/reddit/r_conservative_posts.jsonl\n",
      "38,243 - 100.00% - elapsed: 470.50ms - remaining: 0s - 12.3µs/row     \n"
     ]
    }
   ],
   "source": [
    "path = '../data/raw/reddit/r_conservative_posts.jsonl'\n",
    "processPostFile(path, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file ../data/raw/reddit/r_progressive_posts.jsonl\n",
      "320 - 100.00% - elapsed: 5.99ms - remaining: 0s - 18.7µs/row\n"
     ]
    }
   ],
   "source": [
    "path = '../data/raw/reddit/r_progressive_posts.jsonl'\n",
    "processPostFile(path, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processCommentFile(path: str, post_id_path: str):\n",
    "\n",
    "    post_ids = set()\n",
    "    with open(post_id_path, \"r\") as f:\n",
    "        for line in f:\n",
    "            post_ids.add(line.strip())\n",
    "\t\n",
    "    new_json = []\n",
    "\n",
    "    filename = os.path.basename(path)\n",
    "    month = ''\n",
    "    if len(filename.split(\"_\")) > 3:\n",
    "        month = filename.split(\"_\")[3].split('.')[0] + '_'\n",
    "        \n",
    "\n",
    "    print(f\"Processing file {path}\")\n",
    "    with open(path, \"rb\") as f:\n",
    "        jsonStream = getFileJsonStream(path, f)\n",
    "        if jsonStream is None:\n",
    "            print(f\"Skipping unknown file {path}\")\n",
    "            return\n",
    "        progressLog = FileProgressLog(path, f)\n",
    "        for row in jsonStream:\n",
    "            progressLog.onRow()\n",
    "            # PUT YOUR CODE HERE\n",
    "            link_id = row[\"link_id\"]\n",
    "\n",
    "            if link_id not in post_ids:\n",
    "                continue\n",
    "            \n",
    "            body = row[\"body\"]\n",
    "\n",
    "            if body == \"[deleted]\" or body == \"[removed]\":\n",
    "                continue\n",
    "            \n",
    "\n",
    "            # comments only\n",
    "            body = row[\"body\"]\n",
    "            parent = row[\"parent_id\"]\n",
    "            created = row[\"created_utc\"]\n",
    "            datetime_object = datetime.fromtimestamp(created)\n",
    "            score = row[\"score\"]\n",
    "            upvotes = row[\"ups\"]\n",
    "            author = row[\"author\"]\n",
    "            subreddit = row[\"subreddit\"]\n",
    "            id = row[\"name\"]\n",
    "\n",
    "            new_json.append({\n",
    "                \"subreddit\": subreddit,\n",
    "                \"post_id\": link_id,\n",
    "                \"id\": id,\n",
    "                \"parent\": parent,\n",
    "                \"author\": author,\n",
    "                \"created\": created,\n",
    "                \"datetime\": str(datetime_object),\n",
    "                \"score\": score,\n",
    "                \"upvotes\": upvotes,\n",
    "                \"body\": body\n",
    "            })\n",
    "        progressLog.logProgress(\"\\n\")\n",
    "    with open(f'../data/filtered/comments/r_{subreddit}_{month}comments.json', \"w\") as f:\n",
    "        for row in new_json:\n",
    "            f.write(json.dumps(row))\n",
    "            f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file ../data/raw/reddit/r_politics_comments_june.jsonl\n",
      "760,573 - 100.00% - elapsed: 00:00:04 - remaining: 0s - 6.4µs/row     \n",
      "Processing file ../data/raw/reddit/r_politics_comments_july.jsonl\n",
      "2,046,229 - 100.00% - elapsed: 00:00:13 - remaining: 0s - 6.5µs/row     \n",
      "Processing file ../data/raw/reddit/r_politics_comments_august.jsonl\n",
      "1,538,001 - 100.00% - elapsed: 00:00:10 - remaining: 0s - 6.6µs/row     \n",
      "Processing file ../data/raw/reddit/r_politics_comments_september.jsonl\n",
      "1,147,472 - 100.00% - elapsed: 00:00:07 - remaining: 0s - 6.3µs/row     \n"
     ]
    }
   ],
   "source": [
    "id_path = '../data/filtered/posts/r_politics_post_ids.txt'\n",
    "for month in ['june', 'july', 'august', 'september']:\n",
    "    path = f'../data/raw/reddit/r_politics_comments_{month}.jsonl'\n",
    "    processCommentFile(path, id_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file ../data/raw/reddit/r_conservative_comments.jsonl\n",
      "685,579 - 100.00% - elapsed: 00:00:04 - remaining: 0s - 6.0µs/row     \n"
     ]
    }
   ],
   "source": [
    "path = f'../data/raw/reddit/r_conservative_comments.jsonl'\n",
    "id_path = '../data/filtered/posts/r_Conservative_post_ids.txt'\n",
    "processCommentFile(path, id_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file ../data/raw/reddit/r_progressive_comments.jsonl\n",
      "815 - 100.00% - elapsed: 5.00ms - remaining: 0s - 6.1µs/row\n"
     ]
    }
   ],
   "source": [
    "path = f'../data/raw/reddit/r_progressive_comments.jsonl'\n",
    "id_path = '../data/filtered/posts/r_progressive_post_ids.txt'\n",
    "processCommentFile(path, id_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_fields_posts = [\n",
    "    \"subreddit\",\n",
    "    \"subreddit_id\",\n",
    "    \"id\",\n",
    "    \"name\",\n",
    "    \"author\",\n",
    "    \"created_utc\",\n",
    "    \"score\",\n",
    "    \"upvote_ratio\",\n",
    "    \"title\",\n",
    "    \"selftext\",\n",
    "    \"url\"\n",
    "]\n",
    "\n",
    "used_fields_comments = [\n",
    "    \"subreddit\",\n",
    "    \"link_id\",\n",
    "    \"name\",\n",
    "    \"parent_id\",\n",
    "    \"author\",\n",
    "    \"created_utc\",\n",
    "    \"score\",\n",
    "    \"ups\",\n",
    "    \"body\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'banned_at_utc', 'archived', 'hide_score', 'ups', 'media_embed', 'upvote_ratio', 'distinguished', 'link_flair_text_color', 'no_follow', 'awarders', 'whitelist_status', 'can_mod_post', 'contest_mode', 'author_cakeday', 'secure_media', 'hidden', 'num_comments', 'content_categories', '_meta', 'pwls', 'author_flair_text', 'subreddit_subscribers', 'removed_by', 'selftext', 'author_patreon_flair', 'link_flair_richtext', 'thumbnail_height', 'downs', 'top_awarded_type', 'link_flair_template_id', 'wls', 'category', 'view_count', 'author_fullname', 'removed_by_category', 'crosspost_parent', 'preview', 'quarantine', 'url', 'num_reports', 'send_replies', 'author_flair_css_class', 'num_crossposts', 'crosspost_parent_list', 'removal_reason', 'discussion_type', 'all_awardings', 'visited', 'author_flair_template_id', 'domain', 'user_reports', 'link_flair_type', 'approved_at_utc', 'created_utc', 'is_video', 'pinned', 'treatment_tags', 'subreddit_type', 'total_awards_received', 'created', 'author_flair_background_color', 'gildings', 'thumbnail', 'banned_by', 'author_premium', 'score', 'gilded', 'author_flair_text_color', 'mod_reports', 'title', 'mod_reason_title', 'url_overridden_by_dest', 'author', 'subreddit_id', 'is_self', 'media', 'author_flair_type', 'mod_reason_by', 'permalink', 'is_reddit_media_domain', 'suggested_sort', 'saved', 'allow_live_comments', 'stickied', 'is_created_from_ads_ui', 'retrieved_on', 'likes', 'is_meta', 'subreddit_name_prefixed', 'thumbnail_width', 'secure_media_embed', 'is_original_content', 'name', 'author_flair_richtext', 'link_flair_text', 'over_18', 'subreddit', 'mod_note', 'link_flair_css_class', 'link_flair_background_color', 'can_gild', 'post_hint', 'media_only', 'spoiler', 'edited', 'clicked', 'approved_by', 'is_crosspostable', 'report_reasons', 'parent_whitelist_status', 'is_robot_indexable', 'locked', 'id', 'author_is_blocked'}\n",
      "{'subreddit_type', 'collapsed_reason_code', 'subreddit_name_prefixed', 'banned_at_utc', 'author_fullname', 'total_awards_received', 'collapsed_reason', 'archived', 'associated_award', 'is_submitter', 'treatment_tags', 'ups', 'created', 'author_flair_background_color', 'author_flair_richtext', 'distinguished', 'name', 'gildings', 'replies', 'banned_by', 'no_follow', 'author_premium', 'awarders', 'score', 'collapsed', 'can_mod_post', 'num_reports', 'author_cakeday', 'link_id', 'gilded', 'send_replies', 'subreddit', 'author_flair_css_class', 'mod_note', 'author_flair_text_color', 'collapsed_because_crowd_control', 'mod_reports', 'removal_reason', '_meta', 'media_metadata', 'mod_reason_title', 'author', 'all_awardings', 'controversiality', 'subreddit_id', 'author_flair_type', 'author_flair_text', 'mod_reason_by', 'can_gild', 'author_flair_template_id', 'permalink', 'unrepliable_reason', 'user_reports', 'expression_asset_data', 'comment_type', 'edited', 'approved_by', 'author_patreon_flair', 'score_hidden', 'saved', 'report_reasons', 'downs', 'stickied', 'approved_at_utc', 'top_awarded_type', 'editable', 'created_utc', 'parent_id', 'retrieved_on', 'locked', 'likes', 'body', 'id', 'author_is_blocked'}\n"
     ]
    }
   ],
   "source": [
    "unused_fields_posts = []\n",
    "\n",
    "with open('../data/raw/reddit/r_politics_posts.jsonl', 'rb') as f:\n",
    "    set_fields = set()\n",
    "    for row in getFileJsonStream('../data/raw/reddit/r_politics_posts.jsonl', f):\n",
    "        for key in row.keys():\n",
    "            set_fields.add(key)\n",
    "    print(set_fields)\n",
    "    for field in set_fields:\n",
    "        if field not in used_fields_posts:\n",
    "            unused_fields_posts.append(field)\n",
    "\n",
    "unused_fields_comments = []\n",
    "\n",
    "with open('../data/raw/reddit/r_politics_comments_june.jsonl', 'rb') as f:\n",
    "    set_fields = set()\n",
    "    for row in getFileJsonStream('../data/raw/reddit/r_politics_comments_june.jsonl', f):\n",
    "        for key in row.keys():\n",
    "            set_fields.add(key)\n",
    "    print(set_fields)\n",
    "    for field in set_fields:\n",
    "        if field not in used_fields_comments:\n",
    "            unused_fields_comments.append(field)\n",
    "\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/filtered/unused_fields_posts.txt', 'w') as f:\n",
    "    for field in unused_fields_posts:\n",
    "        f.write(\"`\"+field + \"`, \")\n",
    "\n",
    "with open('../data/filtered/unused_fields_comments.txt', 'w') as f:\n",
    "    for field in unused_fields_comments:\n",
    "        f.write(\"`\"+field + \"`, \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sample_1000_lines(path: str):\n",
    "    with open(path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        new_path = '..'+f\"{path[2:].split('.')[0]}_sample.jsonl\"\n",
    "        print(new_path)\n",
    "        with open(new_path, 'w') as f:\n",
    "            for i in range(1001):\n",
    "                f.write(lines[i])\n",
    "\n",
    "docs = ['r_conservative_comments.jsonl',\n",
    "        'r_politics_comments_august.jsonl',\n",
    "        'r_politics_comments_july.jsonl',\n",
    "        'r_politics_comments_june.jsonl',\n",
    "        'r_politics_comments_september.jsonl']\n",
    "\n",
    "for doc in docs:\n",
    "    generate_sample_1000_lines(f'../data/raw/reddit/{doc}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reddit_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
